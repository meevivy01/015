name: JobThai Scraper Uni

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
on:
  workflow_dispatch:      # 1. ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡∏î‡∏£‡∏±‡∏ô‡πÄ‡∏≠‡∏á (Manual Run)
  schedule:
    - cron: '0 17 * * *'   # 2. ‡∏£‡∏±‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏ï‡∏≠‡∏ô 00:00 ‡∏ô. ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ (UTC 17:00)

jobs:
  scrape_job:
    runs-on: ubuntu-latest
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Timezone ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ Hot/New)
    env:
      TZ: 'Asia/Bangkok'

    steps:
      # 1. ‡∏î‡∏∂‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å GitHub ‡∏°‡∏≤‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πà Server
      - name: Checkout code
        uses: actions/checkout@v4

      # 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 3. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Google Chrome (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
      - name: Install Google Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      # 4. ‡∏•‡∏á Library ‡∏ï‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå requirements.txt
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
      # 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Config ‡πÅ‡∏•‡∏∞ .env (‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏±‡∏î JSON ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå .env)
      - name: Create Config & Env Files
        env:
          DATA_COMP: ${{ secrets.COMPETITORS_DATA }}
          DATA_CLIENT: ${{ secrets.CLIENTS_DATA }}
          DATA_TIER1: ${{ secrets.TIER1_DATA }}
        run: |
          # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå yaml (‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏û‡∏±‡∏á)
          echo "$DATA_COMP" > compe.yaml
          echo "$DATA_CLIENT" > co.yaml
          echo "$DATA_TIER1" > tier1.yaml
          
        
          
          touch User.env
          echo "JOBTHAI_USER=${{ secrets.JOBTHAI_USER }}" >> User.env
          echo "JOBTHAI_PASS=${{ secrets.JOBTHAI_PASS }}" >> User.env
          echo "EMAIL_SENDER=${{ secrets.EMAIL_SENDER }}" >> User.env
          echo "EMAIL_PASSWORD=${{ secrets.EMAIL_PASSWORD }}" >> User.env
          echo "EMAIL_RECEIVER=${{ secrets.EMAIL_RECEIVER }}" >> User.env
          
          # ‚ùå ‡∏•‡∏ö 2 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡∏Ñ‡∏£‡∏±‡∏ö (‡∏ï‡∏±‡∏ß‡∏ï‡πâ‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏õ‡∏±‡∏ç‡∏´‡∏≤)
          # echo "G_SHEET_KEY=..." >> User.env
          # echo "G_SHEET_NAME=..." >> User.env

      # 6. ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î Python
      - name: Run Scraper
        env:
          JOBTHAI_USER: ${{ secrets.JOBTHAI_USER }}
          JOBTHAI_PASS: ${{ secrets.JOBTHAI_PASS }}
          EMAIL_SENDER: ${{ secrets.EMAIL_SENDER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_RECEIVER: ${{ secrets.EMAIL_RECEIVER }}
          COOKIES_JSON: ${{ secrets.COOKIES_JSON }}
          GITHUB_EVENT_NAME: ${{ github.event_name }}
          
          # üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏° 2 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ (‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÉ‡∏´‡πâ Python)
          G_SHEET_KEY: ${{ secrets.G_SHEET_KEY }}
          G_SHEET_NAME: ${{ secrets.G_SHEET_NAME }}
          
        run: python Git1.py

      # 7. ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
      - name: Upload Results (CSV & Images)
        if: always() # ‡∏£‡∏±‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏™‡∏°‡∏≠ ‡πÅ‡∏°‡πâ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞ Error ‡∏Å‡∏•‡∏≤‡∏á‡∏ó‡∏≤‡∏á
        uses: actions/upload-artifact@v4
        with:
          name: scraper-results
          path: |
            *.csv
            resume_images/
            *.png  
          retention-days: 1
